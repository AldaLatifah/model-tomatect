{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"private/tomatect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private/tomatect/bacterial_spot\n",
      "private/tomatect/early_blight\n",
      "private/tomatect/healthy\n",
      "private/tomatect/leaf_mold\n",
      "private/tomatect/spider_mites\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "classes = ['bacterial_spot', 'early_blight', 'healthy', 'leaf_mold', 'spider_mites']\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    print(class_path)\n",
    "    for image_name in os.listdir(class_path):\n",
    "        if image_name.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = Image.open(image_path)\n",
    "            image = image.resize((256, 256))  # Resize the image to a desired size\n",
    "            image = np.array(image)\n",
    "            images.append(image)\n",
    "            labels.append(classes.index(class_name))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the dataset: 512\n"
     ]
    }
   ],
   "source": [
    "# Check if the dataset is empty\n",
    "if len(images) == 0:\n",
    "    print(\"Dataset is empty. Please check the dataset directory.\")\n",
    "else:\n",
    "    print(\"Number of samples in the dataset:\", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 409\n",
      "Number of testing samples: 103\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples:\", len(X_train))\n",
    "print(\"Number of testing samples:\", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples:\n",
      "(256, 256, 3) 1\n",
      "(256, 256, 4) 1\n",
      "(256, 256, 4) 3\n",
      "(256, 256, 3) 0\n",
      "(256, 256, 4) 4\n",
      "Testing examples:\n",
      "(256, 256, 4) 0\n",
      "(256, 256, 4) 4\n",
      "(256, 256, 3) 3\n",
      "(256, 256, 3) 2\n",
      "(256, 256, 4) 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Training examples:\")\n",
    "for img, label in zip(X_train[:5], y_train[:5]):\n",
    "    print(img.shape, label)\n",
    "\n",
    "print(\"Testing examples:\")\n",
    "for img, label in zip(X_test[:5], y_test[:5]):\n",
    "    print(img.shape, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in X_train:\n",
    "    print(filepath)\n",
    "\n",
    "X_train = np.array([np.array(Image.open(filepath).convert(\"RGB\")) for filepath in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/dev/my_test_project/myvenv/lib/python3.10/site-packages/PIL/Image.py:3240\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3239\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3240\u001b[0m     fp\u001b[39m.\u001b[39;49mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_paths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(X_train)\n\u001b[0;32m----> 3\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(filepath)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m filepath \u001b[39min\u001b[39;00m X_train_paths])\n\u001b[1;32m      4\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(filepath)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m filepath \u001b[39min\u001b[39;00m X_test])\n\u001b[1;32m      6\u001b[0m \u001b[39m# Convert labels to arrays\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train_paths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(X_train)\n\u001b[0;32m----> 3\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39;49mopen(filepath)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m filepath \u001b[39min\u001b[39;00m X_train_paths])\n\u001b[1;32m      4\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39mopen(filepath)\u001b[39m.\u001b[39mconvert(\u001b[39m\"\u001b[39m\u001b[39mRGB\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mfor\u001b[39;00m filepath \u001b[39min\u001b[39;00m X_test])\n\u001b[1;32m      6\u001b[0m \u001b[39m# Convert labels to arrays\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/my_test_project/myvenv/lib/python3.10/site-packages/PIL/Image.py:3242\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3240\u001b[0m     fp\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   3241\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, io\u001b[39m.\u001b[39mUnsupportedOperation):\n\u001b[0;32m-> 3242\u001b[0m     fp \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(fp\u001b[39m.\u001b[39;49mread())\n\u001b[1;32m   3243\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3245\u001b[0m prefix \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mread(\u001b[39m16\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "X_train_paths = list(X_train)\n",
    "\n",
    "X_train = np.array([np.array(Image.open(filepath).convert(\"RGB\")) for filepath in X_train_paths])\n",
    "X_test = np.array([np.array(Image.open(filepath).convert(\"RGB\")) for filepath in X_test])\n",
    "\n",
    "# Convert labels to arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 0\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([np.array(img) for img in X_train])\n",
    "y_train = np.array(y_train)\n",
    "print(\"Number of training examples:\", len(X_train))\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,  # Randomly rotate the images\n",
    "    width_shift_range=0.2,  # Randomly shift the images horizontally\n",
    "    height_shift_range=0.2,  # Randomly shift the images vertically\n",
    "    horizontal_flip=True  # Randomly flip the images horizontally\n",
    ")\n",
    "# # Fit the data augmentation generator to the training data\n",
    "# if len(X_train) > 0:\n",
    "#     datagen.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(classes), activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No training data available.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "if len(X_train) > 0:\n",
    "    # Perform data augmentation\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "              steps_per_epoch=len(X_train) // batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(np.array(X_test), np.array(y_test)))\n",
    "else:\n",
    "    print(\"No training data available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
