{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import legacy\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'private/tomatect'\n",
    "base_dir = 'private/splits'\n",
    "train_pct = 0.8\n",
    "validation_pct = 0.15\n",
    "test_pct = 0.05\n",
    "img_width = 150\n",
    "img_height = 150\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.makedirs(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.makedirs(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    \n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    os.makedirs(train_class_dir)\n",
    "    \n",
    "    validation_class_dir = os.path.join(validation_dir, class_name)\n",
    "    os.makedirs(validation_class_dir)\n",
    "    \n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    os.makedirs(test_class_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    \n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    validation_class_dir = os.path.join(validation_dir, class_name)\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    \n",
    "    all_files = os.listdir(class_dir)\n",
    "    num_files = len(all_files)\n",
    "    \n",
    "    num_train = int(num_files * train_pct)\n",
    "    num_validation = int(num_files * validation_pct)\n",
    "    num_test = int(num_files * test_pct)\n",
    "    \n",
    "    random.shuffle(all_files)\n",
    "    \n",
    "    train_files = all_files[:num_train]\n",
    "    validation_files = all_files[num_train:num_train+num_validation]\n",
    "    test_files = all_files[-num_test:]\n",
    "    \n",
    "    for file_name in train_files:\n",
    "        src_file = os.path.join(class_dir, file_name)\n",
    "        dst_file = os.path.join(train_class_dir, file_name)\n",
    "        shutil.copyfile(src_file, dst_file)\n",
    "    \n",
    "    for file_name in validation_files:\n",
    "        src_file = os.path.join(class_dir, file_name)\n",
    "        dst_file = os.path.join(validation_class_dir, file_name)\n",
    "        shutil.copyfile(src_file, dst_file)\n",
    "    \n",
    "    for file_name in test_files:\n",
    "        src_file = os.path.join(class_dir, file_name)\n",
    "        dst_file = os.path.join(test_class_dir, file_name)\n",
    "        shutil.copyfile(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 files belonging to 5 classes.\n",
      "Found 30 files belonging to 5 classes.\n",
      "Found 9 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataset_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "dataset_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=123,\n",
    "    shuffle=False,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset_train.class_names\n",
    "\n",
    "dataset_train = dataset_train.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "dataset_validation = dataset_validation.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "dataset_test = dataset_test.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaling = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "   tf.keras.layers.experimental.preprocessing.RandomRotation(0.9),\n",
    "   tf.keras.layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomHeight(0.2),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomWidth(0.2)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset_train.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (batch_size, img_width, img_height, 3)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    data_scaling,\n",
    "  #  data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=16,  kernel_size = (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=16,  kernel_size = (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout((0.2)),\n",
    "    # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    # tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_8 (Sequential)   (32, 150, 150, 3)         0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (32, 148, 148, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPooli  (32, 74, 74, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (32, 72, 72, 16)          4624      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (32, 36, 36, 16)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (32, 34, 34, 16)          2320      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (32, 17, 17, 16)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (32, 17, 17, 16)          0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (32, 4624)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (32, 64)                  296000    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (32, 10)                  650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 304490 (1.16 MB)\n",
      "Trainable params: 304490 (1.16 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=input_shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 20:36:23.048004: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [183]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-06 20:36:23.048405: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [183]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-06 20:36:23.307053: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - ETA: 0s - loss: 1.9113 - accuracy: 0.1639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 20:36:26.300749: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [30]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-06 20:36:26.301109: I tensorflow/core/common_runtime/executor.cc:1210] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [30]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-06-06 20:36:26.356648: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 4s 231ms/step - loss: 1.9113 - accuracy: 0.1639 - val_loss: 1.6551 - val_accuracy: 0.2000\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s 62ms/step - loss: 1.6072 - accuracy: 0.2350 - val_loss: 1.6307 - val_accuracy: 0.2000\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 1.4718 - accuracy: 0.3716 - val_loss: 1.5399 - val_accuracy: 0.2667\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 1.2846 - accuracy: 0.4863 - val_loss: 1.7272 - val_accuracy: 0.2333\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 1.2243 - accuracy: 0.4973 - val_loss: 1.5441 - val_accuracy: 0.4000\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 1.0352 - accuracy: 0.5956 - val_loss: 1.7202 - val_accuracy: 0.2000\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.9625 - accuracy: 0.6612 - val_loss: 1.5475 - val_accuracy: 0.3333\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 1s 104ms/step - loss: 0.9207 - accuracy: 0.6393 - val_loss: 1.5078 - val_accuracy: 0.4000\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s 87ms/step - loss: 0.7388 - accuracy: 0.6831 - val_loss: 1.5071 - val_accuracy: 0.3667\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.5939 - accuracy: 0.7869 - val_loss: 1.7905 - val_accuracy: 0.3667\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 1s 90ms/step - loss: 0.5761 - accuracy: 0.7814 - val_loss: 1.6932 - val_accuracy: 0.4000\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 0.5056 - accuracy: 0.8087 - val_loss: 1.5660 - val_accuracy: 0.4667\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 0.3578 - accuracy: 0.8907 - val_loss: 1.6980 - val_accuracy: 0.4000\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 1s 94ms/step - loss: 0.2984 - accuracy: 0.9071 - val_loss: 2.2116 - val_accuracy: 0.3333\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 1s 93ms/step - loss: 0.2582 - accuracy: 0.9454 - val_loss: 1.7439 - val_accuracy: 0.4667\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.1953 - accuracy: 0.9563 - val_loss: 1.7710 - val_accuracy: 0.3333\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.1573 - accuracy: 0.9672 - val_loss: 2.2686 - val_accuracy: 0.4333\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.1872 - accuracy: 0.9563 - val_loss: 2.1613 - val_accuracy: 0.4333\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.1159 - accuracy: 0.9727 - val_loss: 2.4278 - val_accuracy: 0.4333\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.0936 - accuracy: 1.0000 - val_loss: 2.2607 - val_accuracy: 0.3333\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 1s 80ms/step - loss: 0.0977 - accuracy: 0.9836 - val_loss: 2.2276 - val_accuracy: 0.4000\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 0s 77ms/step - loss: 0.0773 - accuracy: 0.9891 - val_loss: 2.2278 - val_accuracy: 0.4000\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 0.1145 - accuracy: 0.9781 - val_loss: 2.2844 - val_accuracy: 0.4333\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 0s 81ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 2.3346 - val_accuracy: 0.4000\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.0417 - accuracy: 0.9945 - val_loss: 2.4145 - val_accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    batch_size=32,\n",
    "    #steps_per_epoch=len(dataset_test)// batch_size,\n",
    "    validation_data=dataset_validation,\n",
    "    verbose=1,\n",
    "    epochs=25,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
