{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import legacy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'private/tomatect'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_folder in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(class_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = np.array(image_paths)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, class_indices = np.unique(labels, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "recalls = []\n",
    "precisions = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 21:18:54.322762: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-14 21:18:54.323168: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "        tf.keras.layers.experimental.preprocessing.RandomContrast(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "      data_augmentation,\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same', input_shape=(150, 150, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(128, activation='relu'),\n",
    "      tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 150\n",
    "image_height = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image: private/tomatect/spider_mites/.DS_Store\n",
      "Failed to load image: private/tomatect/leaf_mold/.DS_Store\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(image_paths, class_indices):\n",
    "    X_train_paths, X_test_paths = image_paths[train_index], image_paths[test_index]\n",
    "    y_train, y_test = class_indices[train_index], class_indices[test_index]\n",
    "\n",
    "    # Load and preprocess images for training\n",
    "    X_train = []\n",
    "    for image_path in X_train_paths:\n",
    "      image = cv2.imread(image_path)\n",
    "      if image is None:\n",
    "        print(\"Failed to load image:\", image_path)\n",
    "      else:\n",
    "        # Resize and preprocess the image\n",
    "        preprocessed_image = cv2.resize(image, (image_width, image_height))\n",
    "        preprocessed_image = image / 255.0  # Normalize the image\n",
    "        X_train.append(preprocessed_image)\n",
    "    X_train = np.array(X_train)\n",
    "\n",
    "    # Load and preprocess images for testing\n",
    "    X_test = []\n",
    "    for image_path in X_test_paths:\n",
    "      image = cv2.imread(image_path)\n",
    "      if image is None:\n",
    "        print(\"Failed to load image:\", image_path)\n",
    "      else:\n",
    "        # Resize and preprocess the image\n",
    "        preprocessed_image = cv2.resize(image, (image_width, image_height))\n",
    "        preprocessed_image = image / 255.0  # Normalize the image\n",
    "        X_test.append(preprocessed_image)\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    # Convert class labels to one-hot encoded vectors\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "X_train.shape()\n",
    "y_train.shape()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
