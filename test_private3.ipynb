{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "# from tensorflow.keras.optimizers import legacy\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'private/tomatect'\n",
    "base_dir = 'private/splits'\n",
    "train_pct = 0.8\n",
    "validation_pct = 0.15\n",
    "test_pct = 0.05\n",
    "img_width = 150\n",
    "img_height = 150\n",
    "batch_size = 16\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 183 files belonging to 5 classes.\n",
      "Found 30 files belonging to 5 classes.\n",
      "Found 9 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "dataset_validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    seed=123,\n",
    "    shuffle=True,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "\n",
    "dataset_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    seed=123,\n",
    "    shuffle=False,\n",
    "    image_size=(img_height,img_width),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset_train.class_names\n",
    "\n",
    "dataset_train = dataset_train.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "dataset_validation = dataset_validation.cache().shuffle(1000).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "dataset_test = dataset_test.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaling = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Resizing(img_height, img_width),\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "   tf.keras.layers.experimental.preprocessing.RandomRotation(0.9),\n",
    "   tf.keras.layers.experimental.preprocessing.RandomContrast(0.5),\n",
    "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset_train.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y)\n",
    ").prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (batch_size, img_width, img_height, 3)\n",
    "n_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    data_scaling,\n",
    "  #  data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, kernel_size = (3,3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_6 (Sequential)   (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (16, 148, 148, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPooli  (16, 74, 74, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (16, 72, 72, 64)          18496     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPooli  (16, 36, 36, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (16, 34, 34, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPooli  (16, 17, 17, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (16, 18496)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (16, 64)                  1183808   \n",
      "                                                                 \n",
      " dense_15 (Dense)            (16, 5)                   325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1240453 (4.73 MB)\n",
      "Trainable params: 1240453 (4.73 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(input_shape=input_shape)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_validation\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_PrefetchDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dataset_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 21:39:23.811494: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/12 [==========================>...] - ETA: 0s - loss: 1.6421 - accuracy: 0.1916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 21:39:25.236305: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 112ms/step - loss: 1.6343 - accuracy: 0.2022 - val_loss: 1.5859 - val_accuracy: 0.2667\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 1.5394 - accuracy: 0.3169 - val_loss: 1.5442 - val_accuracy: 0.3000\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.3994 - accuracy: 0.3661 - val_loss: 1.5635 - val_accuracy: 0.1667\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 1.3246 - accuracy: 0.4208 - val_loss: 1.7005 - val_accuracy: 0.2000\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 1.2611 - accuracy: 0.5137 - val_loss: 1.6108 - val_accuracy: 0.2333\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 1.1008 - accuracy: 0.5956 - val_loss: 1.4765 - val_accuracy: 0.3333\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.8403 - accuracy: 0.7268 - val_loss: 1.4166 - val_accuracy: 0.4667\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.7431 - accuracy: 0.7158 - val_loss: 1.4244 - val_accuracy: 0.4000\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.5414 - accuracy: 0.8197 - val_loss: 1.7724 - val_accuracy: 0.5333\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.4995 - accuracy: 0.8251 - val_loss: 1.6416 - val_accuracy: 0.3333\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.2930 - accuracy: 0.9016 - val_loss: 1.9826 - val_accuracy: 0.4333\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.2006 - accuracy: 0.9508 - val_loss: 1.8458 - val_accuracy: 0.3667\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.1769 - accuracy: 0.9454 - val_loss: 2.1978 - val_accuracy: 0.3667\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 1s 93ms/step - loss: 0.1823 - accuracy: 0.9344 - val_loss: 2.5561 - val_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.1100 - accuracy: 0.9617 - val_loss: 2.7598 - val_accuracy: 0.3333\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0788 - accuracy: 0.9781 - val_loss: 2.4396 - val_accuracy: 0.4667\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 2.6692 - val_accuracy: 0.4000\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0464 - accuracy: 0.9836 - val_loss: 2.6117 - val_accuracy: 0.3667\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 1s 78ms/step - loss: 0.0287 - accuracy: 0.9945 - val_loss: 2.5891 - val_accuracy: 0.4667\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 3.2272 - val_accuracy: 0.4333\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.3629 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.3897 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4538 - val_accuracy: 0.4667\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 9.5128e-04 - accuracy: 1.0000 - val_loss: 3.5441 - val_accuracy: 0.4667\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 7.8845e-04 - accuracy: 1.0000 - val_loss: 3.6049 - val_accuracy: 0.4667\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 6.7661e-04 - accuracy: 1.0000 - val_loss: 3.6512 - val_accuracy: 0.4667\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 6.0864e-04 - accuracy: 1.0000 - val_loss: 3.6793 - val_accuracy: 0.4667\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 1s 96ms/step - loss: 5.5000e-04 - accuracy: 1.0000 - val_loss: 3.7145 - val_accuracy: 0.4667\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 5.0370e-04 - accuracy: 1.0000 - val_loss: 3.7423 - val_accuracy: 0.4667\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 4.5987e-04 - accuracy: 1.0000 - val_loss: 3.7854 - val_accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    batch_size=16,\n",
    "    #steps_per_epoch=len(dataset_test)// batch_size,\n",
    "    validation_data=dataset_validation,\n",
    "    verbose=1,\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 5.155430793762207\n",
      "Validation accuracy: 0.2222222238779068\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(dataset_test, verbose=0)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = dataset_test.map(lambda image, label:label)\n",
    "label_test = np.concatenate([label.numpy() for _, label in dataset_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 21:41:00.585484: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(dataset_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 1]\n",
      " [0 0 2 0 0]\n",
      " [1 0 0 0 0]\n",
      " [1 0 1 0 0]\n",
      " [0 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "con_mat = confusion_matrix(label_test, y_pred)\n",
    "print(con_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
