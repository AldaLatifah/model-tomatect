{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan path ke direktori data\n",
    "data_dir = 'private/tomatect/'\n",
    "classes = ['bacterial_spot', 'early_blight', 'healthy', 'leaf_mold', 'spider_mites']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentukan parameter untuk pembagian data\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inisialisasi list untuk menyimpan data train, validation, dan test\n",
    "train_images = []\n",
    "train_labels = []\n",
    "val_images = []\n",
    "val_labels = []\n",
    "test_images = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop melalui setiap kelas\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    images = os.listdir(class_dir)\n",
    "    random.shuffle(images)\n",
    "    \n",
    "    # Hitung jumlah data pada setiap split\n",
    "    num_images = len(images)\n",
    "    num_train = int(num_images * train_ratio)\n",
    "    num_val = int(num_images * val_ratio)\n",
    "    num_test = num_images - num_train - num_val\n",
    "    \n",
    "    # Bagi data menjadi train, validation, dan test\n",
    "    train_images.extend(images[:num_train])\n",
    "    train_labels.extend([class_name] * num_train)\n",
    "    val_images.extend(images[num_train:num_train+num_val])\n",
    "    val_labels.extend([class_name] * num_val)\n",
    "    test_images.extend(images[num_train+num_val:])\n",
    "    test_labels.extend([class_name] * num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi objek ImageDataGenerator dengan augmentasi yang diinginkan\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=(0.8, 1.2),\n",
    "    rotation_range=90\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memuat dan augmentasi citra\n",
    "def load_and_augment_image(file_path):\n",
    "    image = cv2.imread(file_path)\n",
    "    image = cv2.resize(image, (256, 256))  # Resize citra sesuai dengan kebutuhan Anda\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Konversi dari BGR ke RGB\n",
    "    image = datagen.random_transform(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi generator untuk menghasilkan citra secara batch\n",
    "def image_generator(image_paths, labels, batch_size=32):\n",
    "    num_samples = len(image_paths)\n",
    "    while True:\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        batch_start = 0\n",
    "        while batch_start < num_samples:\n",
    "            batch_indices = indices[batch_start:batch_start+batch_size]\n",
    "            batch_images = [load_and_augment_image(image_paths[i]) for i in batch_indices]\n",
    "            batch_labels = [labels[i] for i in batch_indices]\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n",
    "            batch_start += batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 23:11:56.733258: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-06-06 23:11:56.733597: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 32)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(classes), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat generator untuk data train, validation, dan test\n",
    "train_generator = image_generator(train_images, train_labels, batch_size=32)\n",
    "val_generator = image_generator(val_images, val_labels, batch_size=32)\n",
    "test_generator = image_generator(test_images, test_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung jumlah batch per epoch\n",
    "steps_per_epoch = len(train_images) // 32\n",
    "validation_steps = len(val_images) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'leaf_mold_30.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Pelatihan model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m           validation_data\u001b[39m=\u001b[39;49mval_generator, validation_steps\u001b[39m=\u001b[39;49mvalidation_steps)\n",
      "File \u001b[0;32m~/dev/my_test_project/myvenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36mimage_generator\u001b[0;34m(image_paths, labels, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m batch_start \u001b[39m<\u001b[39m num_samples:\n\u001b[1;32m      7\u001b[0m     batch_indices \u001b[39m=\u001b[39m indices[batch_start:batch_start\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m----> 8\u001b[0m     batch_images \u001b[39m=\u001b[39m [load_and_augment_image(image_paths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m batch_indices]\n\u001b[1;32m      9\u001b[0m     batch_labels \u001b[39m=\u001b[39m [labels[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m batch_indices]\n\u001b[1;32m     10\u001b[0m     \u001b[39myield\u001b[39;00m np\u001b[39m.\u001b[39marray(batch_images), np\u001b[39m.\u001b[39marray(batch_labels)\n",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mwhile\u001b[39;00m batch_start \u001b[39m<\u001b[39m num_samples:\n\u001b[1;32m      7\u001b[0m     batch_indices \u001b[39m=\u001b[39m indices[batch_start:batch_start\u001b[39m+\u001b[39mbatch_size]\n\u001b[0;32m----> 8\u001b[0m     batch_images \u001b[39m=\u001b[39m [load_and_augment_image(image_paths[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m batch_indices]\n\u001b[1;32m      9\u001b[0m     batch_labels \u001b[39m=\u001b[39m [labels[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m batch_indices]\n\u001b[1;32m     10\u001b[0m     \u001b[39myield\u001b[39;00m np\u001b[39m.\u001b[39marray(batch_images), np\u001b[39m.\u001b[39marray(batch_labels)\n",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m, in \u001b[0;36mload_and_augment_image\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_and_augment_image\u001b[39m(file_path):\n\u001b[0;32m----> 3\u001b[0m     image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(file_path)\n\u001b[1;32m      4\u001b[0m     image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(image)\n\u001b[1;32m      5\u001b[0m     image \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39mrandom_transform(image)\n",
      "File \u001b[0;32m~/dev/my_test_project/myvenv/lib/python3.10/site-packages/PIL/Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[1;32m   3235\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[0;32m-> 3236\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   3237\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   3239\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'leaf_mold_30.jpg'"
     ]
    }
   ],
   "source": [
    "# Pelatihan model\n",
    "history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=10,\n",
    "          validation_data=val_generator, validation_steps=validation_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
